---
title: "caret_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{caret_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# install.packages("caret")
# install.packages("mlbench")

library(BonusLab)
library(mlbench)
library(MASS)
library(tidyverse)
library(caret)

ridgereg <- getFromNamespace("ridgereg", "BonusLab")

```

Use the caret package and the 'ridgereg()' function to create a predictive model for the [BostonHousing] data found in the [mlbench] package. 


## caret example

Divide the BostonHousing data into a test and training dataset using the caret package.
```{r}

data("BostonHousing")

train_indices <- createDataPartition(BostonHousing$crim, times = 1, p = 0.8, list = FALSE, groups = 2)

# create training set
train_data <- BostonHousing[train_indices,]

# create testing set
test_data  <- BostonHousing[-train_indices,]

```

Fit a linear regression model and fit a linear regression model with forward selection of covariates on the training dataset.

```{r}

# Fit a linear regression model on the training dataset
saturated_model <- lm(medv ~ ., data = train_data)
summary(saturated_model)


# Fit a linear regression model with forward selection on the training dataset
null_model <- lm(medv ~ 1, data = train_data)

lm_forward_model <- stepAIC(null_model, direction = "forward",
                            scope = list(lower = null_model, 
                                         upper = saturated_model), trace = FALSE)
summary(lm_forward_model)

```


Evaluate the performance of this model on the training dataset.
```{r}

broom::glance(saturated_model) %>%
  dplyr::select(r.squared, adj.r.squared, sigma, AIC, BIC, p.value)
broom::glance(lm_forward_model) %>%
  dplyr::select(r.squared, adj.r.squared, sigma, AIC, BIC, p.value)

sum((round(predict(saturated_model,train_data),1)-train_data$medv)^2)
sum((round(predict(lm_forward_model,train_data),1)-train_data$medv)^2)

```


Fit a ridge regression model using your ridgereg() function to the training dataset for different values of lambda. 
```{r}

ridgereg_model_lambda0_01 <- ridgereg(medv ~ .,data=train_data,lambda=0.01)
ridgereg_model_lambda0_02 <- ridgereg(medv ~ .,data=train_data,lambda=0.02)
ridgereg_model_lambda0_05 <- ridgereg(medv ~ .,data=train_data,lambda=0.05)
ridgereg_model_lambda0_1 <- ridgereg(medv ~ .,data=train_data,lambda=0.1)

sum((round(ridgereg_model_lambda0_01$pred(),1)-train_data$medv)^2)
sum((round(ridgereg_model_lambda0_02$pred(),1)-train_data$medv)^2)
sum((round(ridgereg_model_lambda0_05$pred(),1)-train_data$medv)^2)
sum((round(ridgereg_model_lambda0_1$pred(),1)-train_data$medv)^2)

```


Find the best hyperparameter value for lambda using 10-fold cross-validation on the training set. 
```{r}

# 
# kfolds <- 10
# train_n <- nrow(train_data)
# 
# folds_index <- createFolds(train_data$crim, k = 10, list = TRUE, returnTrain = TRUE)
# 
# 
# test <- train_data[as.vector(folds_index[[1]]),]
# 
# 
# 
# cv_err <- rep(0, kfolds)
# 
# for(lambda in seq(0,0.1, by=0.01)){
#   for(i in 1:kfolds){
#   in_data <- train_data[as.vector(folds_index[[i]]),]
#   out_data <- train_data[-as.vector(folds_index[[1]]),]
#   
#   fit <- ridgereg(medv ~ ., in_data, lambda)
#   preds <- predict(fit, out_data)
#   
#   err <- out_data$medv - preds
#   mse <- mean(err^2)
#   # Record the RMSE
#   cv_err[i] <- sqrt(mse)
#   }
# }
# 
#   



```


Evaluate the performance of all three models on the test dataset and write some concluding comments.
```{r}

sum((round(predict(saturated_model,test_data),1)-test_data$medv)^2)
sum((round(predict(lm_forward_model,test_data),1)-test_data$medv)^2)
# sum((round(predict(lm_model_bestlambda,test_data),1)-test_data$medv)^2)


```


